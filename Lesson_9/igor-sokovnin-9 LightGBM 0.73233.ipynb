{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# Модель\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefull Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_cross_validation(params, X, y, cv, categorical = None):\n",
    "    # Кросс-валидация модели catboost\n",
    "    estimartors, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    \n",
    "    print(f\"{time.ctime()}, Cross-validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "    X[categorical] = X[categorical].astype(str)\n",
    "    #X[categorical] = X[categorical].astype('S32')\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "        \n",
    "        model = cb.CatBoostClassifier(**params)\n",
    "        model.fit(\n",
    "            x_train, y_train, categorical,\n",
    "            eval_set=[(x_train, y_train), (x_valid, y_valid)]\n",
    "        )\n",
    "        oof_preds[valid_idx] = model.predict_proba(x_valid)[:, 1]\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimartors.append(model)\n",
    "            \n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    \n",
    "    return estimartors, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_cross_validation_1(params, X, y, cv, categorical = None):\n",
    "    # Кросс-валидация модели lightgbm\n",
    "    estimartors, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    \n",
    "    print(f\"{time.ctime()}, Cross-validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X=x_train[numerical + categorical],\n",
    "            y=y_train,\n",
    "            eval_set=[(x_train[numerical + categorical], y_train), (x_valid[numerical + categorical], y_valid)],\n",
    "            categorical_feature = categorical,\n",
    "            early_stopping_rounds=50,\n",
    "            eval_metric=\"auc\",\n",
    "            verbose=50\n",
    "        )\n",
    "    \n",
    "        oof_preds[valid_idx] = model.predict_proba(x_valid)[:, 1]\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimartors.append(model)\n",
    "            \n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    \n",
    "    return estimartors, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_cross_validation(params, X, y, cv, categorical = None):\n",
    "    # Кросс-валидация модели lightgbm\n",
    "    estimartors, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    \n",
    "    print(f\"{time.ctime()}, Cross-validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "    if isinstance(categorial, list):\n",
    "        X[categorial] = X[categorial].astype(pd.category)\n",
    "        categorical = categorical\n",
    "    else:\n",
    "        catigorical = \"auto\"\n",
    "    \n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X=x_train,\n",
    "            y=y_train,\n",
    "            categorical_feature = categorical,\n",
    "            eval_set=[(x_train, y_train), (x_valid, y_valid)],\n",
    "            eval_names=[\"dtrain\", \"dvalid\"],\n",
    "            early_stopping_rounds=100,\n",
    "            eval_metric=\"auc\",\n",
    "            verbose=25\n",
    "        )\n",
    "    \n",
    "        oof_preds[valid_idx] = model.predict_proba(x_valid)[:, 1]\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimartors.append(model)\n",
    "            \n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    \n",
    "    return estimartors, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_profile_features(X: pd.DataFrame, copy: bool = True) -> pd.DataFrame:\n",
    "    # Создание признака на основе профиля клиентов.\n",
    "    \n",
    "    # AMOUNT_CREDIT - сумма кредита\n",
    "    # AMOUNT_ANNUITY - сумма платежа\n",
    "    if copy:\n",
    "        X = X.copy()\n",
    "        \n",
    "    X[\"DAYS_ON_LAST_JOB\"] = X[\"DAYS_ON_LAST_JOB\"].replace(365243, np.nan)\n",
    "    bki_flags = [flag for flag in X.columns if \"AMT_REQ_CREDIT_BUREAU\" in flag]\n",
    "    X[\"bki_requests_count\"] = X[bki_flags].sum(axis=1)\n",
    "    X[\"bki_kurtosis\"] = X[bki_flags].kurtosis(axis=1)\n",
    "    \n",
    "    X[\"external_scoring_prod\"] = X[\"EXTERNAL_SCORING_RATING_1\"] * X[\"EXTERNAL_SCORING_RATING_2\"] * X[\"EXTERNAL_SCORING_RATING_3\"]\n",
    "    X[\"external_scoring_weighted\"] = X.EXTERNAL_SCORING_RATING_1 * 2 + X.EXTERNAL_SCORING_RATING_2 * 1 + X.EXTERNAL_SCORING_RATING_3 * 3\n",
    "    \n",
    "    for function_name in [\"min\", \"max\", \"mean\", \"nanmedian\", \"var\"]:\n",
    "        feature_name = \"external_scoring_rating_{}\".format(function_name)\n",
    "        X[feature_name] = eval(\"np.{}\".format(function_name))(\n",
    "            X[[\"EXTERNAL_SCORING_RATING_1\", \"EXTERNAL_SCORING_RATING_2\", \"EXTERNAL_SCORING_RATING_3\"]], axis=1\n",
    "        )\n",
    "        \n",
    "    # Отношение между основными фин. показателями\n",
    "    X[\"ratio_credit_to_annuity\"] = X[\"AMOUNT_CREDIT\"] / X[\"AMOUNT_ANNUITY\"]\n",
    "    X[\"ratio_annuity_to_salary\"] = X[\"AMOUNT_ANNUITY\"] / X[\"TOTAL_SALARY\"]\n",
    "    X[\"ratio_credit_to_salary\"] = X[\"AMOUNT_CREDIT\"] / X[\"TOTAL_SALARY\"]\n",
    "    \n",
    "    # Отношение фин. показателей к возрасту и временным фичам\n",
    "    X[\"ratio_annuity_to_age\"] = X[\"AMOUNT_ANNUITY\"] / X[\"AGE\"]\n",
    "    X[\"ratio_credit_to_age\"] = X[\"AMOUNT_CREDIT\"] / X[\"AGE\"]\n",
    "    X[\"ratio_salary_to_age\"] = X[\"TOTAL_SALARY\"] / X[\"AGE\"]\n",
    "    X[\"ratio_salary_to_experience\"] = X[\"TOTAL_SALARY\"] / X[\"DAYS_ON_LAST_JOB\"]\n",
    "    X[\"ratio_credit_to_experience\"] = X[\"AMOUNT_CREDIT\"] / X[\"DAYS_ON_LAST_JOB\"]\n",
    "    X[\"ratio_annuity_to_experience\"] = X[\"AMOUNT_ANNUITY\"] / X[\"DAYS_ON_LAST_JOB\"]\n",
    "    \n",
    "    # Отношения временных признаков\n",
    "    X[\"ratio_age_to_experience\"] = X[\"AGE\"] / X[\"DAYS_ON_LAST_JOB\"]\n",
    "    X[\"ratio_salary_to_region_population\"] = X[\"TOTAL_SALARY\"] / X[\"REGION_POPULATION\"]\n",
    "    X[\"ratio_car_to_experience\"] = X[\"OWN_CAR_AGE\"] / X[\"DAYS_ON_LAST_JOB\"]\n",
    "    X[\"ratio_car_to_age\"] = X[\"OWN_CAR_AGE\"] / X[\"AGE\"]    \n",
    "    \n",
    "    # Произведение фин. показателей кредита на вероятность дефолта\n",
    "    # Такая штука называется математическим ожиданием дефолта или ожиданиемыми потерями\n",
    "    X[\"expected_total_loss_1\"] = X[\"EXTERNAL_SCORING_RATING_1\"] * X[\"AMOUNT_CREDIT\"]\n",
    "    X[\"expected_total_loss_2\"] = X[\"EXTERNAL_SCORING_RATING_2\"] * X[\"AMOUNT_CREDIT\"]\n",
    "    X[\"expected_total_loss_3\"] = X[\"EXTERNAL_SCORING_RATING_3\"] * X[\"AMOUNT_CREDIT\"]\n",
    "    X[\"expected_monthly_loss_1\"] = X[\"EXTERNAL_SCORING_RATING_1\"] * X[\"AMOUNT_ANNUITY\"]\n",
    "    X[\"expected_monthly_loss_2\"] = X[\"EXTERNAL_SCORING_RATING_2\"] * X[\"AMOUNT_ANNUITY\"]\n",
    "    X[\"expected_monthly_loss_3\"] = X[\"EXTERNAL_SCORING_RATING_3\"] * X[\"AMOUNT_ANNUITY\"]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_catigirical_features(X: pd.DataFrame, copy: bool = True) -> pd.DataFrame:\n",
    "    if copy:\n",
    "        df = X.copy()\n",
    "        \n",
    "        # NAME_CONTRACT_TYPE\n",
    "        cat_colname = 'NAME_CONTRACT_TYPE'\n",
    "        # Years in current job\n",
    "        df[cat_colname] = df[cat_colname].replace(to_replace = np.nan, value = 'неизвестно')\n",
    "\n",
    "        df.loc[df[cat_colname] == 'Cash', cat_colname] = 0\n",
    "        df.loc[df[cat_colname] == 'Credit Card', cat_colname] = 1\n",
    "        df.loc[df[cat_colname] == 'неизвестно', cat_colname] = 2\n",
    "        \n",
    "        # GENDER\n",
    "        cat_colname = 'GENDER'\n",
    "        df[cat_colname] = df[cat_colname].replace(to_replace = np.nan, value = 'неизвестно')\n",
    "        \n",
    "        df.loc[df[cat_colname] == 'F', cat_colname] = 0\n",
    "        df.loc[df[cat_colname] == 'M', cat_colname] = 1\n",
    "        df.loc[df[cat_colname] == 'XNA', cat_colname] = 2\n",
    "        df.loc[df[cat_colname] == 'неизвестно', cat_colname] = 3\n",
    "            \n",
    "        # EDUCATION_LEVEL\n",
    "        cat_colname = 'EDUCATION_LEVEL'\n",
    "        df[cat_colname] = df[cat_colname].replace(to_replace = np.nan, value = 'неизвестно')\n",
    "\n",
    "        df.loc[df[cat_colname] == 'Secondary / secondary special', cat_colname] = 0\n",
    "        df.loc[df[cat_colname] == 'Higher education', cat_colname] = 1\n",
    "        df.loc[df[cat_colname] == 'Incomplete higher', cat_colname] = 2\n",
    "        df.loc[df[cat_colname] == 'Lower secondary', cat_colname] = 3\n",
    "        df.loc[df[cat_colname] == 'Academic degree', cat_colname] = 4\n",
    "        df.loc[df[cat_colname] == 'неизвестно', cat_colname] = 5\n",
    "        \n",
    "        # FAMILY_STATUS\n",
    "        cat_colname = 'FAMILY_STATUS'\n",
    "        df[cat_colname] = df[cat_colname].replace(to_replace = np.nan, value = 'неизвестно')\n",
    "        \n",
    "        df.loc[df[cat_colname] == 'Married', cat_colname] = 0\n",
    "        df.loc[df[cat_colname] == 'Single / not married', cat_colname] = 1\n",
    "        df.loc[df[cat_colname] == 'Civil marriage', cat_colname] = 2\n",
    "        df.loc[df[cat_colname] == 'Separated', cat_colname] = 3\n",
    "        df.loc[df[cat_colname] == 'Widow', cat_colname] = 4\n",
    "        df.loc[df[cat_colname] == 'Separated', cat_colname] = 5\n",
    "        df.loc[df[cat_colname] == 'Unknown', cat_colname] = 6\n",
    "        df.loc[df[cat_colname] == 'неизвестно', cat_colname] = 7\n",
    "        \n",
    "        # CREDIT_DEBT\n",
    "        cat_colname = 'CREDIT_DEBT'\n",
    "        df[cat_colname] = df[cat_colname].replace(to_replace = np.nan, value = 0)\n",
    "        \n",
    "        # Обработка категорий\n",
    "        for colname in ['NAME_CONTRACT_TYPE', 'GENDER', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'CREDIT_DEBT']:\n",
    "            df[colname] = df[colname].astype('int8')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Description__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для построения модели в данном соревновании, сначала нужно будет собрать выборку для обучения модели. Формат соревнования очень похож на то, как в промышленности Data Scinetist'ы строят алгоритмы: сначала нужно провести анализ данных, собрать выборку и после этого строить модели. В соревновании представлены 4 типы источника данных, которые могут быть интерпретированы как таблицы в базе данных. Некоторые источники данных уже готовы для моделирования, представлены в агрерированном виде. Другие источники данных требуется представить в удобном для модели виде.\n",
    "\n",
    "__Описание источников данных:__\n",
    "\n",
    "- train.csv - пары \"заявка - целевая переменная\", для этой выборки нужно собрать признаки и обучить модель;\n",
    "- test.csv - пары \"заявки - прогнозное значение\", для этой выборки нужно собрать признаки и построить прогнозы;\n",
    "- bki.csv - данные БКИ о предыдущих кредитах клиента;\n",
    "- client_profile.csv - клиентский профиль, некоторые знания, которые есть у компании о клиенте;\n",
    "- payments.csv - история платежей клиента;\n",
    "- applications_history.csv - история предыдущих заявок клиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/kaggle/input/geekbrains-competitive-data-analysis/\"\n",
    "\n",
    "TRAIN_DATASET_PATH = base_path + 'train.csv'\n",
    "TEST_DATASET_PATH = base_path + 'test.csv'\n",
    "bki_DATASET_PATH = base_path + 'bki.csv'\n",
    "applications_history_DATASET_PATH = base_path + 'applications_history.csv'\n",
    "client_profile_DATASET_PATH = base_path + 'client_profile.csv'\n",
    "payments_DATASET_PATH = base_path + 'payments.csv'\n",
    "sample_submit_DATASET_PATH = base_path + 'sample_submit.csv'\n",
    "\n",
    "ID_COLUMN = \"APPLICATION_NUMBER\"\n",
    "ID_COLUMN_PR = \"PREV_APPLICATION_NUMBER\"\n",
    "TARGET = \"TARGET\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110093, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_NUMBER</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123687442</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123597908</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_NUMBER  TARGET NAME_CONTRACT_TYPE\n",
       "0           123687442       0               Cash\n",
       "1           123597908       1               Cash"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. train.csv - пары \"заявка - целевая переменная\", для этой выборки нужно собрать признаки и обучить модель;\n",
    "train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "print(train.shape)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165141, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_NUMBER</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123724268</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123456549</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_NUMBER NAME_CONTRACT_TYPE\n",
       "0           123724268               Cash\n",
       "1           123456549               Cash"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. test.csv - пары \"заявки - прогнозное значение\", для этой выборки нужно собрать признаки и построить прогнозы;\n",
    "test = pd.read_csv(TEST_DATASET_PATH)\n",
    "print(test.shape)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275234, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_NUMBER</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123687442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123597908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_NUMBER  TARGET NAME_CONTRACT_TYPE\n",
       "0           123687442     0.0               Cash\n",
       "1           123597908     1.0               Cash"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train, test], axis = 0)\n",
    "data.reset_index(drop=True)\n",
    "print(data.shape)\n",
    "data.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### client_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input)\n"
     ]
    }
   ],
   "source": [
    "# 4. client_profile.csv - клиентский профиль\n",
    "client_profile = pd.read_csv(client_profile_DATASET_PATH)\n",
    "df_client_profile = create_client_profile_features(client_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_NUMBER</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>CHILDRENS</th>\n",
       "      <th>TOTAL_SALARY</th>\n",
       "      <th>AMOUNT_CREDIT</th>\n",
       "      <th>AMOUNT_ANNUITY</th>\n",
       "      <th>EDUCATION_LEVEL</th>\n",
       "      <th>FAMILY_STATUS</th>\n",
       "      <th>REGION_POPULATION</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DAYS_ON_LAST_JOB</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_credit_to_age</th>\n",
       "      <th>ratio_salary_to_age</th>\n",
       "      <th>ratio_salary_to_experience</th>\n",
       "      <th>ratio_credit_to_experience</th>\n",
       "      <th>ratio_annuity_to_experience</th>\n",
       "      <th>ratio_age_to_experience</th>\n",
       "      <th>ratio_salary_to_region_population</th>\n",
       "      <th>ratio_car_to_experience</th>\n",
       "      <th>ratio_car_to_age</th>\n",
       "      <th>expected_total_loss_1</th>\n",
       "      <th>expected_total_loss_2</th>\n",
       "      <th>expected_total_loss_3</th>\n",
       "      <th>expected_monthly_loss_1</th>\n",
       "      <th>expected_monthly_loss_2</th>\n",
       "      <th>expected_monthly_loss_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123687442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>855000.0</td>\n",
       "      <td>25128.0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>15728.0</td>\n",
       "      <td>1719.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.361648</td>\n",
       "      <td>10.013988</td>\n",
       "      <td>91.623037</td>\n",
       "      <td>497.382199</td>\n",
       "      <td>14.617801</td>\n",
       "      <td>9.149506</td>\n",
       "      <td>8.245642e+06</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>599170.547652</td>\n",
       "      <td>552256.266546</td>\n",
       "      <td>612667.559305</td>\n",
       "      <td>17609.307043</td>\n",
       "      <td>16230.521013</td>\n",
       "      <td>18005.977111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123597908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_NUMBER  TARGET NAME_CONTRACT_TYPE GENDER  CHILDRENS  \\\n",
       "0           123687442     0.0               Cash      M        1.0   \n",
       "1           123597908     1.0               Cash    NaN        NaN   \n",
       "\n",
       "   TOTAL_SALARY  AMOUNT_CREDIT  AMOUNT_ANNUITY                EDUCATION_LEVEL  \\\n",
       "0      157500.0       855000.0         25128.0  Secondary / secondary special   \n",
       "1           NaN            NaN             NaN                            NaN   \n",
       "\n",
       "  FAMILY_STATUS  REGION_POPULATION      AGE  DAYS_ON_LAST_JOB  OWN_CAR_AGE  \\\n",
       "0       Married           0.019101  15728.0            1719.0         11.0   \n",
       "1           NaN                NaN      NaN               NaN          NaN   \n",
       "\n",
       "   FLAG_PHONE  ...  ratio_credit_to_age  ratio_salary_to_age  \\\n",
       "0         0.0  ...            54.361648            10.013988   \n",
       "1         NaN  ...                  NaN                  NaN   \n",
       "\n",
       "   ratio_salary_to_experience  ratio_credit_to_experience  \\\n",
       "0                   91.623037                  497.382199   \n",
       "1                         NaN                         NaN   \n",
       "\n",
       "   ratio_annuity_to_experience  ratio_age_to_experience  \\\n",
       "0                    14.617801                 9.149506   \n",
       "1                          NaN                      NaN   \n",
       "\n",
       "   ratio_salary_to_region_population  ratio_car_to_experience  \\\n",
       "0                       8.245642e+06                 0.006399   \n",
       "1                                NaN                      NaN   \n",
       "\n",
       "   ratio_car_to_age  expected_total_loss_1  expected_total_loss_2  \\\n",
       "0          0.000699          599170.547652          552256.266546   \n",
       "1               NaN                    NaN                    NaN   \n",
       "\n",
       "   expected_total_loss_3  expected_monthly_loss_1  expected_monthly_loss_2  \\\n",
       "0          612667.559305             17609.307043             16230.521013   \n",
       "1                    NaN                      NaN                      NaN   \n",
       "\n",
       "   expected_monthly_loss_3  \n",
       "0             18005.977111  \n",
       "1                      NaN  \n",
       "\n",
       "[2 rows x 54 columns]"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.merge(\n",
    "    df_client_profile, how=\"left\", on=\"APPLICATION_NUMBER\"\n",
    ")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(945234, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_NUMBER</th>\n",
       "      <th>BUREAU_ID</th>\n",
       "      <th>CREDIT_ACTIVE</th>\n",
       "      <th>CREDIT_CURRENCY</th>\n",
       "      <th>DAYS_CREDIT</th>\n",
       "      <th>CREDIT_DAY_OVERDUE</th>\n",
       "      <th>DAYS_CREDIT_ENDDATE</th>\n",
       "      <th>DAYS_ENDDATE_FACT</th>\n",
       "      <th>AMT_CREDIT_MAX_OVERDUE</th>\n",
       "      <th>CNT_CREDIT_PROLONG</th>\n",
       "      <th>AMT_CREDIT_SUM</th>\n",
       "      <th>AMT_CREDIT_SUM_DEBT</th>\n",
       "      <th>AMT_CREDIT_SUM_LIMIT</th>\n",
       "      <th>AMT_CREDIT_SUM_OVERDUE</th>\n",
       "      <th>CREDIT_TYPE</th>\n",
       "      <th>DAYS_CREDIT_UPDATE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123538884</td>\n",
       "      <td>5223613</td>\n",
       "      <td>Active</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>718.0</td>\n",
       "      <td>0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19386.81</td>\n",
       "      <td>0</td>\n",
       "      <td>675000.00</td>\n",
       "      <td>320265.495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consumer credit</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123436670</td>\n",
       "      <td>6207544</td>\n",
       "      <td>Closed</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>696.0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>93111.66</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consumer credit</td>\n",
       "      <td>505.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_NUMBER  BUREAU_ID CREDIT_ACTIVE CREDIT_CURRENCY  DAYS_CREDIT  \\\n",
       "0           123538884    5223613        Active      currency 1        718.0   \n",
       "1           123436670    6207544        Closed      currency 1        696.0   \n",
       "\n",
       "   CREDIT_DAY_OVERDUE  DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  \\\n",
       "0                   0                377.0                NaN   \n",
       "1                   0                511.0              511.0   \n",
       "\n",
       "   AMT_CREDIT_MAX_OVERDUE  CNT_CREDIT_PROLONG  AMT_CREDIT_SUM  \\\n",
       "0                19386.81                   0       675000.00   \n",
       "1                    0.00                   0        93111.66   \n",
       "\n",
       "   AMT_CREDIT_SUM_DEBT  AMT_CREDIT_SUM_LIMIT  AMT_CREDIT_SUM_OVERDUE  \\\n",
       "0           320265.495                   0.0                     0.0   \n",
       "1                0.000                   0.0                     0.0   \n",
       "\n",
       "       CREDIT_TYPE  DAYS_CREDIT_UPDATE  AMT_ANNUITY  \n",
       "0  Consumer credit                39.0          NaN  \n",
       "1  Consumer credit               505.0          NaN  "
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. bki.csv - данные БКИ о предыдущих кредитах клиента;\n",
    "df_bki = pd.read_csv(bki_DATASET_PATH)\n",
    "print(df_bki.shape)\n",
    "df_bki.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(945234, 17)\n"
     ]
    }
   ],
   "source": [
    "#df_c = df_bki[[\"APPLICATION_NUMBER\", \"AMT_CREDIT_MAX_OVERDUE\"]]\n",
    "df_c = df_bki[[\"APPLICATION_NUMBER\", \"AMT_CREDIT_MAX_OVERDUE\", \"AMT_CREDIT_SUM_LIMIT\", \"AMT_ANNUITY\"]]\n",
    "df = df_bki.groupby('APPLICATION_NUMBER').sum()\n",
    "df['CREDIT_DEBT'] = 1\n",
    "print(df_bki.shape)\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUREAU_ID</th>\n",
       "      <th>DAYS_CREDIT</th>\n",
       "      <th>CREDIT_DAY_OVERDUE</th>\n",
       "      <th>DAYS_CREDIT_ENDDATE</th>\n",
       "      <th>DAYS_ENDDATE_FACT</th>\n",
       "      <th>AMT_CREDIT_MAX_OVERDUE</th>\n",
       "      <th>CNT_CREDIT_PROLONG</th>\n",
       "      <th>AMT_CREDIT_SUM</th>\n",
       "      <th>AMT_CREDIT_SUM_DEBT</th>\n",
       "      <th>AMT_CREDIT_SUM_LIMIT</th>\n",
       "      <th>AMT_CREDIT_SUM_OVERDUE</th>\n",
       "      <th>DAYS_CREDIT_UPDATE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>CREDIT_DEBT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APPLICATION_NUMBER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123779588</th>\n",
       "      <td>59775214</td>\n",
       "      <td>18372.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14640.0</td>\n",
       "      <td>13509.0</td>\n",
       "      <td>30735.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3110411.16</td>\n",
       "      <td>163071.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123779589</th>\n",
       "      <td>6913730</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>483349.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>384147.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123779592</th>\n",
       "      <td>11413155</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2610000.00</td>\n",
       "      <td>1795833.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>58369.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123779593</th>\n",
       "      <td>6723687</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123779594</th>\n",
       "      <td>31130714</td>\n",
       "      <td>6286.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5768.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>16618.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1512994.50</td>\n",
       "      <td>687744.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4208.0</td>\n",
       "      <td>3244.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    BUREAU_ID  DAYS_CREDIT  CREDIT_DAY_OVERDUE  \\\n",
       "APPLICATION_NUMBER                                               \n",
       "123779588            59775214      18372.0                   0   \n",
       "123779589             6913730       1002.0                   0   \n",
       "123779592            11413155       1632.0                   0   \n",
       "123779593             6723687       1104.0                   0   \n",
       "123779594            31130714       6286.0                   0   \n",
       "\n",
       "                    DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  \\\n",
       "APPLICATION_NUMBER                                           \n",
       "123779588                       14640.0            13509.0   \n",
       "123779589                         272.0              760.0   \n",
       "123779592                        1500.0                0.0   \n",
       "123779593                         859.0              859.0   \n",
       "123779594                        5768.0             4250.0   \n",
       "\n",
       "                    AMT_CREDIT_MAX_OVERDUE  CNT_CREDIT_PROLONG  \\\n",
       "APPLICATION_NUMBER                                               \n",
       "123779588                          30735.0                   0   \n",
       "123779589                              0.0                   0   \n",
       "123779592                              0.0                   0   \n",
       "123779593                              0.0                   0   \n",
       "123779594                          16618.5                   0   \n",
       "\n",
       "                    AMT_CREDIT_SUM  AMT_CREDIT_SUM_DEBT  AMT_CREDIT_SUM_LIMIT  \\\n",
       "APPLICATION_NUMBER                                                              \n",
       "123779588               3110411.16            163071.00                   0.0   \n",
       "123779589                483349.50                 0.00                   0.0   \n",
       "123779592               2610000.00           1795833.00                   0.0   \n",
       "123779593                 45000.00                 0.00                   0.0   \n",
       "123779594               1512994.50            687744.54                   0.0   \n",
       "\n",
       "                    AMT_CREDIT_SUM_OVERDUE  DAYS_CREDIT_UPDATE  AMT_ANNUITY  \\\n",
       "APPLICATION_NUMBER                                                            \n",
       "123779588                              0.0             12160.0          0.0   \n",
       "123779589                              0.0               127.0     384147.0   \n",
       "123779592                              0.0               184.0      58369.5   \n",
       "123779593                              0.0               401.0          0.0   \n",
       "123779594                              0.0              4208.0       3244.5   \n",
       "\n",
       "                    CREDIT_DEBT  \n",
       "APPLICATION_NUMBER               \n",
       "123779588                     1  \n",
       "123779589                     1  \n",
       "123779592                     1  \n",
       "123779593                     1  \n",
       "123779594                     1  "
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bki_columns = df_bki[[\"APPLICATION_NUMBER\", \"AMT_CREDIT_MAX_OVERDUE\", \"AMT_CREDIT_SUM_LIMIT\", \"AMT_ANNUITY\"]]\n",
    "# df = df_bki.groupby('APPLICATION_NUMBER').sum()\n",
    "# df['CREDIT_DEBT'] = 1\n",
    "# df.head(2)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('AMT_CREDIT_MAX_OVERDUE', axis=1, inplace=True)\n",
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275234, 54)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data = data.merge(\n",
    "    df, how=\"left\", on=\"APPLICATION_NUMBER\"\n",
    ")\n",
    "# print(data.shape)\n",
    "# print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = data[\"TARGET\"].isnull()\n",
    "# features_to_drop = [\"APPLICATION_NUMBER\", \"TARGET\"]\n",
    "\n",
    "# train, test = data.loc[~mask], data.loc[mask]\n",
    "\n",
    "# target, test_id = train[\"TARGET\"], test[\"APPLICATION_NUMBER\"]\n",
    "# train = train.drop(features_to_drop, axis=1)\n",
    "# test = test.drop(features_to_drop, axis=1)\n",
    "\n",
    "# # categorial = train.dtypes[train.dtypes == \"category\"].index\n",
    "# categorial = train.dtypes[train.dtypes == \"object\"].index\n",
    "\n",
    "# # categoriсal = list(set(categorial + categorial_1))\n",
    "# numerical = list(set(train.columns) - set(categorial))\n",
    "\n",
    "# ###\n",
    "# train = new_catigirical_features(train)\n",
    "# test = new_catigirical_features(test)\n",
    "# ###\n",
    "\n",
    "# train = train.replace(np.inf, np.nan)\n",
    "# train = train.replace(-np.inf, np.nan)\n",
    "\n",
    "# print(categorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CatBoost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_params = {\n",
    "    \"n_estimators\": 2000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"max_bin\": 20,\n",
    "    \"l2_leaf_reg\": 10,\n",
    "    \"verbose\": 20,\n",
    "    \"max_depth\": 6,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"thread_count\": 6,\n",
    "    \"random_seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = KFold(n_splits=7, random_state=1234123, shuffle=True)\n",
    "# estimators, oof_preds = catboost_cross_validation(\n",
    "#     params=cb_params, X=train, y=target, cv=cv, categorical=categorial\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data[\"TARGET\"].isnull()\n",
    "features_to_drop = [\"APPLICATION_NUMBER\", \"TARGET\"]\n",
    "categorial = data.dtypes[data.dtypes == \"object\"].index\n",
    "numerical = list(set(train.columns) - set(categorial))\n",
    "\n",
    "for feature in categorial:\n",
    "    encoder = LabelEncoder()\n",
    "    data[feature] = encoder.fit_transform(data[feature].astype(\"str\").fillna(\"NA\"))\n",
    "\n",
    "train, test = data.loc[~mask], data.loc[mask]\n",
    "target, train_id, test_id = train[\"TARGET\"], train[\"APPLICATION_NUMBER\"], test[\"APPLICATION_NUMBER\"]\n",
    "train = train.drop(features_to_drop, axis=1)\n",
    "test = test.drop(features_to_drop, axis=1)\n",
    "\n",
    "\n",
    "###\n",
    "train = new_catigirical_features(train)\n",
    "test = new_catigirical_features(test)\n",
    "###\n",
    "\n",
    "train = train.replace(np.inf, np.nan)\n",
    "train = train.replace(-np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test.info())\n",
    "#test.head(2)\n",
    "# print(train.info())\n",
    "# train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"n_estimators\": 10000,  # число деревьев\n",
    "    \"learning_rate\": 0.05134,\n",
    "    \"num_leaves\": 54,\n",
    "    \"max_depth\": 10,  # глубина дерева\n",
    "    \"subsample_for_bin\": 240000,\n",
    "    \"reg_alpha\": 0.436193,\n",
    "    \"reg_lambda\": 0.479169,  # регуляризация (то что используется при F2-штрафе (1:15:10))\n",
    "    \"colsample_bytree\": 0.508716,\n",
    "    \"min_split_gain\": 0.024766,\n",
    "    \"subsample\": 0.7,\n",
    "    \"is_unbalance\": False,\n",
    "    \"random_state\": 27,\n",
    "    \"silent\": -1,\n",
    "    \"verbose\": 1,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAME_CONTRACT_TYPE',\n",
       " 'GENDER',\n",
       " 'EDUCATION_LEVEL',\n",
       " 'FAMILY_STATUS',\n",
       " 'CREDIT_DEBT']"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical=list(categorial)\n",
    "categorical.append('CREDIT_DEBT')\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 23 14:37:46 2021, Cross-validation, 110093 rows, 66 cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8282, number of negative: 94471\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11872\n",
      "[LightGBM] [Info] Number of data points in the train set: 102753, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080601 -> initscore=-2.434208\n",
      "[LightGBM] [Info] Start training from score -2.434208\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.749328\tdtrain's binary_logloss: 0.251231\tdvalid's auc: 0.701825\tdvalid's binary_logloss: 0.266907\n",
      "[50]\tdtrain's auc: 0.774797\tdtrain's binary_logloss: 0.241629\tdvalid's auc: 0.707603\tdvalid's binary_logloss: 0.264183\n",
      "[75]\tdtrain's auc: 0.794728\tdtrain's binary_logloss: 0.23491\tdvalid's auc: 0.709185\tdvalid's binary_logloss: 0.263793\n",
      "[100]\tdtrain's auc: 0.813199\tdtrain's binary_logloss: 0.229171\tdvalid's auc: 0.710928\tdvalid's binary_logloss: 0.263542\n",
      "[125]\tdtrain's auc: 0.828286\tdtrain's binary_logloss: 0.224299\tdvalid's auc: 0.710567\tdvalid's binary_logloss: 0.263587\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tdtrain's auc: 0.841701\tdtrain's binary_logloss: 0.220013\tdvalid's auc: 0.71067\tdvalid's binary_logloss: 0.263694\n",
      "[175]\tdtrain's auc: 0.854339\tdtrain's binary_logloss: 0.215768\tdvalid's auc: 0.709792\tdvalid's binary_logloss: 0.264097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[97]\tdtrain's auc: 0.810881\tdtrain's binary_logloss: 0.229837\tdvalid's auc: 0.711234\tdvalid's binary_logloss: 0.263525\n",
      "Fold 1, Valid score = 0.71123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8277, number of negative: 94476\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11960\n",
      "[LightGBM] [Info] Number of data points in the train set: 102753, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080552 -> initscore=-2.434865\n",
      "[LightGBM] [Info] Start training from score -2.434865\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.749966\tdtrain's binary_logloss: 0.251351\tdvalid's auc: 0.720144\tdvalid's binary_logloss: 0.266892\n",
      "[50]\tdtrain's auc: 0.774256\tdtrain's binary_logloss: 0.241921\tdvalid's auc: 0.726135\tdvalid's binary_logloss: 0.262736\n",
      "[75]\tdtrain's auc: 0.794782\tdtrain's binary_logloss: 0.23508\tdvalid's auc: 0.73058\tdvalid's binary_logloss: 0.261284\n",
      "[100]\tdtrain's auc: 0.813234\tdtrain's binary_logloss: 0.229394\tdvalid's auc: 0.731143\tdvalid's binary_logloss: 0.260943\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[125]\tdtrain's auc: 0.828138\tdtrain's binary_logloss: 0.224813\tdvalid's auc: 0.731389\tdvalid's binary_logloss: 0.260829\n",
      "[150]\tdtrain's auc: 0.841229\tdtrain's binary_logloss: 0.220421\tdvalid's auc: 0.731263\tdvalid's binary_logloss: 0.260861\n",
      "[175]\tdtrain's auc: 0.85306\tdtrain's binary_logloss: 0.216352\tdvalid's auc: 0.730476\tdvalid's binary_logloss: 0.260921\n",
      "[200]\tdtrain's auc: 0.864349\tdtrain's binary_logloss: 0.212421\tdvalid's auc: 0.728871\tdvalid's binary_logloss: 0.261195\n",
      "[225]\tdtrain's auc: 0.874659\tdtrain's binary_logloss: 0.208665\tdvalid's auc: 0.729549\tdvalid's binary_logloss: 0.261242\n",
      "Early stopping, best iteration is:\n",
      "[145]\tdtrain's auc: 0.838556\tdtrain's binary_logloss: 0.221355\tdvalid's auc: 0.732005\tdvalid's binary_logloss: 0.260892\n",
      "Fold 2, Valid score = 0.73201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8283, number of negative: 94470\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11878\n",
      "[LightGBM] [Info] Number of data points in the train set: 102753, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080611 -> initscore=-2.434077\n",
      "[LightGBM] [Info] Start training from score -2.434077\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.748388\tdtrain's binary_logloss: 0.251462\tdvalid's auc: 0.712683\tdvalid's binary_logloss: 0.266104\n",
      "[50]\tdtrain's auc: 0.774936\tdtrain's binary_logloss: 0.241792\tdvalid's auc: 0.722051\tdvalid's binary_logloss: 0.262511\n",
      "[75]\tdtrain's auc: 0.796237\tdtrain's binary_logloss: 0.234915\tdvalid's auc: 0.725719\tdvalid's binary_logloss: 0.261335\n",
      "[100]\tdtrain's auc: 0.814473\tdtrain's binary_logloss: 0.229222\tdvalid's auc: 0.727328\tdvalid's binary_logloss: 0.260545\n",
      "[125]\tdtrain's auc: 0.829262\tdtrain's binary_logloss: 0.224412\tdvalid's auc: 0.728489\tdvalid's binary_logloss: 0.260497\n",
      "[150]\tdtrain's auc: 0.842921\tdtrain's binary_logloss: 0.21992\tdvalid's auc: 0.727405\tdvalid's binary_logloss: 0.260703\n",
      "[175]\tdtrain's auc: 0.854221\tdtrain's binary_logloss: 0.215985\tdvalid's auc: 0.727074\tdvalid's binary_logloss: 0.260721\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tdtrain's auc: 0.864458\tdtrain's binary_logloss: 0.212359\tdvalid's auc: 0.727382\tdvalid's binary_logloss: 0.260963\n",
      "Early stopping, best iteration is:\n",
      "[108]\tdtrain's auc: 0.819731\tdtrain's binary_logloss: 0.227552\tdvalid's auc: 0.729124\tdvalid's binary_logloss: 0.260384\n",
      "Fold 3, Valid score = 0.72912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8312, number of negative: 94441\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11871\n",
      "[LightGBM] [Info] Number of data points in the train set: 102753, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080893 -> initscore=-2.430275\n",
      "[LightGBM] [Info] Start training from score -2.430275\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.747741\tdtrain's binary_logloss: 0.252247\tdvalid's auc: 0.722802\tdvalid's binary_logloss: 0.255173\n",
      "[50]\tdtrain's auc: 0.773335\tdtrain's binary_logloss: 0.242792\tdvalid's auc: 0.727785\tdvalid's binary_logloss: 0.251198\n",
      "[75]\tdtrain's auc: 0.794842\tdtrain's binary_logloss: 0.235891\tdvalid's auc: 0.730476\tdvalid's binary_logloss: 0.249883\n",
      "[100]\tdtrain's auc: 0.811816\tdtrain's binary_logloss: 0.230315\tdvalid's auc: 0.731374\tdvalid's binary_logloss: 0.249359\n",
      "[125]\tdtrain's auc: 0.826696\tdtrain's binary_logloss: 0.225571\tdvalid's auc: 0.732293\tdvalid's binary_logloss: 0.248982\n",
      "[150]\tdtrain's auc: 0.8402\tdtrain's binary_logloss: 0.221264\tdvalid's auc: 0.731681\tdvalid's binary_logloss: 0.24912\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[175]\tdtrain's auc: 0.852604\tdtrain's binary_logloss: 0.217162\tdvalid's auc: 0.73109\tdvalid's binary_logloss: 0.249206\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tdtrain's auc: 0.863377\tdtrain's binary_logloss: 0.21324\tdvalid's auc: 0.730832\tdvalid's binary_logloss: 0.249433\n",
      "[225]\tdtrain's auc: 0.873072\tdtrain's binary_logloss: 0.209473\tdvalid's auc: 0.72959\tdvalid's binary_logloss: 0.249709\n",
      "Early stopping, best iteration is:\n",
      "[137]\tdtrain's auc: 0.833568\tdtrain's binary_logloss: 0.223522\tdvalid's auc: 0.732514\tdvalid's binary_logloss: 0.248948\n",
      "Fold 4, Valid score = 0.73251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8320, number of negative: 94433\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11966\n",
      "[LightGBM] [Info] Number of data points in the train set: 102753, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080971 -> initscore=-2.429228\n",
      "[LightGBM] [Info] Start training from score -2.429228\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.747487\tdtrain's binary_logloss: 0.252232\tdvalid's auc: 0.713247\tdvalid's binary_logloss: 0.255644\n",
      "[50]\tdtrain's auc: 0.774117\tdtrain's binary_logloss: 0.24258\tdvalid's auc: 0.718394\tdvalid's binary_logloss: 0.252262\n",
      "[75]\tdtrain's auc: 0.795873\tdtrain's binary_logloss: 0.235575\tdvalid's auc: 0.721723\tdvalid's binary_logloss: 0.251283\n",
      "[100]\tdtrain's auc: 0.812902\tdtrain's binary_logloss: 0.229887\tdvalid's auc: 0.721867\tdvalid's binary_logloss: 0.25094\n",
      "[125]\tdtrain's auc: 0.828643\tdtrain's binary_logloss: 0.22514\tdvalid's auc: 0.722353\tdvalid's binary_logloss: 0.250822\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tdtrain's auc: 0.842223\tdtrain's binary_logloss: 0.220743\tdvalid's auc: 0.722504\tdvalid's binary_logloss: 0.251007\n",
      "[175]\tdtrain's auc: 0.854328\tdtrain's binary_logloss: 0.216681\tdvalid's auc: 0.722096\tdvalid's binary_logloss: 0.250934\n",
      "[200]\tdtrain's auc: 0.865197\tdtrain's binary_logloss: 0.212801\tdvalid's auc: 0.723676\tdvalid's binary_logloss: 0.250846\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[225]\tdtrain's auc: 0.875117\tdtrain's binary_logloss: 0.209193\tdvalid's auc: 0.722609\tdvalid's binary_logloss: 0.250958\n",
      "[250]\tdtrain's auc: 0.884654\tdtrain's binary_logloss: 0.205436\tdvalid's auc: 0.723262\tdvalid's binary_logloss: 0.251025\n",
      "[275]\tdtrain's auc: 0.891491\tdtrain's binary_logloss: 0.202312\tdvalid's auc: 0.723288\tdvalid's binary_logloss: 0.251055\n",
      "[300]\tdtrain's auc: 0.898491\tdtrain's binary_logloss: 0.19905\tdvalid's auc: 0.721923\tdvalid's binary_logloss: 0.251327\n",
      "Early stopping, best iteration is:\n",
      "[211]\tdtrain's auc: 0.869567\tdtrain's binary_logloss: 0.21119\tdvalid's auc: 0.723899\tdvalid's binary_logloss: 0.250736\n",
      "Fold 5, Valid score = 0.7239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8317, number of negative: 94436\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11965\n",
      "[LightGBM] [Info] Number of data points in the train set: 102753, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080942 -> initscore=-2.429621\n",
      "[LightGBM] [Info] Start training from score -2.429621\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.749037\tdtrain's binary_logloss: 0.25242\tdvalid's auc: 0.715557\tdvalid's binary_logloss: 0.254536\n",
      "[50]\tdtrain's auc: 0.773907\tdtrain's binary_logloss: 0.242857\tdvalid's auc: 0.719496\tdvalid's binary_logloss: 0.250811\n",
      "[75]\tdtrain's auc: 0.794652\tdtrain's binary_logloss: 0.235852\tdvalid's auc: 0.726724\tdvalid's binary_logloss: 0.249176\n",
      "[100]\tdtrain's auc: 0.811038\tdtrain's binary_logloss: 0.230315\tdvalid's auc: 0.727282\tdvalid's binary_logloss: 0.248831\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[125]\tdtrain's auc: 0.827222\tdtrain's binary_logloss: 0.225611\tdvalid's auc: 0.728613\tdvalid's binary_logloss: 0.248556\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tdtrain's auc: 0.83996\tdtrain's binary_logloss: 0.221383\tdvalid's auc: 0.728789\tdvalid's binary_logloss: 0.248555\n",
      "[175]\tdtrain's auc: 0.852702\tdtrain's binary_logloss: 0.217258\tdvalid's auc: 0.729491\tdvalid's binary_logloss: 0.248346\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tdtrain's auc: 0.862507\tdtrain's binary_logloss: 0.213562\tdvalid's auc: 0.729794\tdvalid's binary_logloss: 0.247917\n",
      "[225]\tdtrain's auc: 0.872562\tdtrain's binary_logloss: 0.209782\tdvalid's auc: 0.72865\tdvalid's binary_logloss: 0.248264\n",
      "[250]\tdtrain's auc: 0.881207\tdtrain's binary_logloss: 0.206083\tdvalid's auc: 0.729571\tdvalid's binary_logloss: 0.248234\n",
      "[275]\tdtrain's auc: 0.889851\tdtrain's binary_logloss: 0.202654\tdvalid's auc: 0.730147\tdvalid's binary_logloss: 0.248196\n",
      "[300]\tdtrain's auc: 0.897197\tdtrain's binary_logloss: 0.19928\tdvalid's auc: 0.731205\tdvalid's binary_logloss: 0.248177\n",
      "Early stopping, best iteration is:\n",
      "[203]\tdtrain's auc: 0.863829\tdtrain's binary_logloss: 0.213133\tdvalid's auc: 0.730037\tdvalid's binary_logloss: 0.247875\n",
      "Fold 6, Valid score = 0.73004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8308, number of negative: 94445\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11965\n",
      "[LightGBM] [Info] Number of data points in the train set: 102753, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080854 -> initscore=-2.430799\n",
      "[LightGBM] [Info] Start training from score -2.430799\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.748726\tdtrain's binary_logloss: 0.252181\tdvalid's auc: 0.717768\tdvalid's binary_logloss: 0.25712\n",
      "[50]\tdtrain's auc: 0.774625\tdtrain's binary_logloss: 0.242506\tdvalid's auc: 0.725278\tdvalid's binary_logloss: 0.253283\n",
      "[75]\tdtrain's auc: 0.795209\tdtrain's binary_logloss: 0.235751\tdvalid's auc: 0.729373\tdvalid's binary_logloss: 0.251694\n",
      "[100]\tdtrain's auc: 0.812335\tdtrain's binary_logloss: 0.230201\tdvalid's auc: 0.729916\tdvalid's binary_logloss: 0.251515\n",
      "[125]\tdtrain's auc: 0.828087\tdtrain's binary_logloss: 0.225205\tdvalid's auc: 0.731519\tdvalid's binary_logloss: 0.251397\n",
      "[150]\tdtrain's auc: 0.841813\tdtrain's binary_logloss: 0.220748\tdvalid's auc: 0.732499\tdvalid's binary_logloss: 0.251298\n",
      "[175]\tdtrain's auc: 0.853148\tdtrain's binary_logloss: 0.216925\tdvalid's auc: 0.731566\tdvalid's binary_logloss: 0.251315\n",
      "[200]\tdtrain's auc: 0.864242\tdtrain's binary_logloss: 0.213026\tdvalid's auc: 0.730686\tdvalid's binary_logloss: 0.251582\n",
      "[225]\tdtrain's auc: 0.874423\tdtrain's binary_logloss: 0.20924\tdvalid's auc: 0.730735\tdvalid's binary_logloss: 0.251542\n",
      "Early stopping, best iteration is:\n",
      "[144]\tdtrain's auc: 0.838845\tdtrain's binary_logloss: 0.221717\tdvalid's auc: 0.732761\tdvalid's binary_logloss: 0.251336\n",
      "Fold 7, Valid score = 0.73276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8295, number of negative: 94458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11967\n",
      "[LightGBM] [Info] Number of data points in the train set: 102753, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080728 -> initscore=-2.432502\n",
      "[LightGBM] [Info] Start training from score -2.432502\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.749029\tdtrain's binary_logloss: 0.251803\tdvalid's auc: 0.725989\tdvalid's binary_logloss: 0.260585\n",
      "[50]\tdtrain's auc: 0.773482\tdtrain's binary_logloss: 0.242398\tdvalid's auc: 0.733998\tdvalid's binary_logloss: 0.255747\n",
      "[75]\tdtrain's auc: 0.7947\tdtrain's binary_logloss: 0.235521\tdvalid's auc: 0.738379\tdvalid's binary_logloss: 0.254023\n",
      "[100]\tdtrain's auc: 0.811624\tdtrain's binary_logloss: 0.229952\tdvalid's auc: 0.73952\tdvalid's binary_logloss: 0.253562\n",
      "[125]\tdtrain's auc: 0.826983\tdtrain's binary_logloss: 0.225203\tdvalid's auc: 0.739436\tdvalid's binary_logloss: 0.253478\n",
      "[150]\tdtrain's auc: 0.840325\tdtrain's binary_logloss: 0.22088\tdvalid's auc: 0.739668\tdvalid's binary_logloss: 0.253477\n",
      "[175]\tdtrain's auc: 0.852618\tdtrain's binary_logloss: 0.216733\tdvalid's auc: 0.739401\tdvalid's binary_logloss: 0.25365\n",
      "[200]\tdtrain's auc: 0.863748\tdtrain's binary_logloss: 0.212886\tdvalid's auc: 0.739983\tdvalid's binary_logloss: 0.253532\n",
      "Early stopping, best iteration is:\n",
      "[118]\tdtrain's auc: 0.822579\tdtrain's binary_logloss: 0.226476\tdvalid's auc: 0.739859\tdvalid's binary_logloss: 0.253342\n",
      "Fold 8, Valid score = 0.73986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8321, number of negative: 94433\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11974\n",
      "[LightGBM] [Info] Number of data points in the train set: 102754, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080980 -> initscore=-2.429108\n",
      "[LightGBM] [Info] Start training from score -2.429108\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.747951\tdtrain's binary_logloss: 0.252412\tdvalid's auc: 0.716479\tdvalid's binary_logloss: 0.254691\n",
      "[50]\tdtrain's auc: 0.774671\tdtrain's binary_logloss: 0.242833\tdvalid's auc: 0.725041\tdvalid's binary_logloss: 0.250838\n",
      "[75]\tdtrain's auc: 0.794573\tdtrain's binary_logloss: 0.235995\tdvalid's auc: 0.727476\tdvalid's binary_logloss: 0.24975\n",
      "[100]\tdtrain's auc: 0.812427\tdtrain's binary_logloss: 0.230426\tdvalid's auc: 0.729503\tdvalid's binary_logloss: 0.249117\n",
      "[125]\tdtrain's auc: 0.827391\tdtrain's binary_logloss: 0.225795\tdvalid's auc: 0.729191\tdvalid's binary_logloss: 0.248971\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tdtrain's auc: 0.84093\tdtrain's binary_logloss: 0.221424\tdvalid's auc: 0.729827\tdvalid's binary_logloss: 0.248957\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[175]\tdtrain's auc: 0.852233\tdtrain's binary_logloss: 0.217411\tdvalid's auc: 0.728375\tdvalid's binary_logloss: 0.249216\n",
      "[200]\tdtrain's auc: 0.862987\tdtrain's binary_logloss: 0.213564\tdvalid's auc: 0.729369\tdvalid's binary_logloss: 0.249148\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[225]\tdtrain's auc: 0.873941\tdtrain's binary_logloss: 0.209618\tdvalid's auc: 0.72919\tdvalid's binary_logloss: 0.249118\n",
      "Early stopping, best iteration is:\n",
      "[142]\tdtrain's auc: 0.837217\tdtrain's binary_logloss: 0.222693\tdvalid's auc: 0.730751\tdvalid's binary_logloss: 0.248853\n",
      "Fold 9, Valid score = 0.73075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8300, number of negative: 94454\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11870\n",
      "[LightGBM] [Info] Number of data points in the train set: 102754, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080775 -> initscore=-2.431857\n",
      "[LightGBM] [Info] Start training from score -2.431857\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.748017\tdtrain's binary_logloss: 0.251914\tdvalid's auc: 0.720848\tdvalid's binary_logloss: 0.259436\n",
      "[50]\tdtrain's auc: 0.77374\tdtrain's binary_logloss: 0.242459\tdvalid's auc: 0.731678\tdvalid's binary_logloss: 0.25507\n",
      "[75]\tdtrain's auc: 0.794609\tdtrain's binary_logloss: 0.235539\tdvalid's auc: 0.737347\tdvalid's binary_logloss: 0.253245\n",
      "[100]\tdtrain's auc: 0.812817\tdtrain's binary_logloss: 0.229868\tdvalid's auc: 0.738169\tdvalid's binary_logloss: 0.2527\n",
      "[125]\tdtrain's auc: 0.828079\tdtrain's binary_logloss: 0.225161\tdvalid's auc: 0.73896\tdvalid's binary_logloss: 0.252415\n",
      "[150]\tdtrain's auc: 0.841017\tdtrain's binary_logloss: 0.220815\tdvalid's auc: 0.739139\tdvalid's binary_logloss: 0.252448\n",
      "[175]\tdtrain's auc: 0.853908\tdtrain's binary_logloss: 0.216723\tdvalid's auc: 0.739809\tdvalid's binary_logloss: 0.252316\n",
      "[200]\tdtrain's auc: 0.865285\tdtrain's binary_logloss: 0.212744\tdvalid's auc: 0.738325\tdvalid's binary_logloss: 0.252508\n",
      "[225]\tdtrain's auc: 0.874096\tdtrain's binary_logloss: 0.209148\tdvalid's auc: 0.738696\tdvalid's binary_logloss: 0.25274\n",
      "[250]\tdtrain's auc: 0.883396\tdtrain's binary_logloss: 0.205576\tdvalid's auc: 0.738444\tdvalid's binary_logloss: 0.252817\n",
      "Early stopping, best iteration is:\n",
      "[172]\tdtrain's auc: 0.852757\tdtrain's binary_logloss: 0.217094\tdvalid's auc: 0.739947\tdvalid's binary_logloss: 0.252281\n",
      "Fold 10, Valid score = 0.73995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8304, number of negative: 94450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11873\n",
      "[LightGBM] [Info] Number of data points in the train set: 102754, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080814 -> initscore=-2.431333\n",
      "[LightGBM] [Info] Start training from score -2.431333\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.748089\tdtrain's binary_logloss: 0.251997\tdvalid's auc: 0.710103\tdvalid's binary_logloss: 0.259028\n",
      "[50]\tdtrain's auc: 0.773664\tdtrain's binary_logloss: 0.242333\tdvalid's auc: 0.716175\tdvalid's binary_logloss: 0.255798\n",
      "[75]\tdtrain's auc: 0.794812\tdtrain's binary_logloss: 0.235584\tdvalid's auc: 0.718657\tdvalid's binary_logloss: 0.254818\n",
      "[100]\tdtrain's auc: 0.811406\tdtrain's binary_logloss: 0.230017\tdvalid's auc: 0.720428\tdvalid's binary_logloss: 0.254887\n",
      "[125]\tdtrain's auc: 0.827349\tdtrain's binary_logloss: 0.225265\tdvalid's auc: 0.719563\tdvalid's binary_logloss: 0.255305\n",
      "[150]\tdtrain's auc: 0.840876\tdtrain's binary_logloss: 0.220943\tdvalid's auc: 0.720066\tdvalid's binary_logloss: 0.255356\n",
      "[175]\tdtrain's auc: 0.853321\tdtrain's binary_logloss: 0.216834\tdvalid's auc: 0.720236\tdvalid's binary_logloss: 0.255306\n",
      "Early stopping, best iteration is:\n",
      "[83]\tdtrain's auc: 0.800385\tdtrain's binary_logloss: 0.233689\tdvalid's auc: 0.719934\tdvalid's binary_logloss: 0.254681\n",
      "Fold 11, Valid score = 0.71993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8339, number of negative: 94415\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11972\n",
      "[LightGBM] [Info] Number of data points in the train set: 102754, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081155 -> initscore=-2.426757\n",
      "[LightGBM] [Info] Start training from score -2.426757\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.748416\tdtrain's binary_logloss: 0.252599\tdvalid's auc: 0.707166\tdvalid's binary_logloss: 0.250184\n",
      "[50]\tdtrain's auc: 0.774849\tdtrain's binary_logloss: 0.242883\tdvalid's auc: 0.711879\tdvalid's binary_logloss: 0.247523\n",
      "[75]\tdtrain's auc: 0.795907\tdtrain's binary_logloss: 0.23596\tdvalid's auc: 0.714454\tdvalid's binary_logloss: 0.246706\n",
      "[100]\tdtrain's auc: 0.814293\tdtrain's binary_logloss: 0.230234\tdvalid's auc: 0.71553\tdvalid's binary_logloss: 0.246249\n",
      "[125]\tdtrain's auc: 0.829075\tdtrain's binary_logloss: 0.225546\tdvalid's auc: 0.71554\tdvalid's binary_logloss: 0.24633\n",
      "[150]\tdtrain's auc: 0.841631\tdtrain's binary_logloss: 0.221175\tdvalid's auc: 0.714777\tdvalid's binary_logloss: 0.246502\n",
      "[175]\tdtrain's auc: 0.852398\tdtrain's binary_logloss: 0.217346\tdvalid's auc: 0.715564\tdvalid's binary_logloss: 0.246554\n",
      "[200]\tdtrain's auc: 0.863332\tdtrain's binary_logloss: 0.213406\tdvalid's auc: 0.71539\tdvalid's binary_logloss: 0.246501\n",
      "Early stopping, best iteration is:\n",
      "[102]\tdtrain's auc: 0.815947\tdtrain's binary_logloss: 0.229758\tdvalid's auc: 0.716507\tdvalid's binary_logloss: 0.24609\n",
      "Fold 12, Valid score = 0.71651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8269, number of negative: 94485\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11966\n",
      "[LightGBM] [Info] Number of data points in the train set: 102754, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080474 -> initscore=-2.435928\n",
      "[LightGBM] [Info] Start training from score -2.435928\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.749583\tdtrain's binary_logloss: 0.251003\tdvalid's auc: 0.688863\tdvalid's binary_logloss: 0.272871\n",
      "[50]\tdtrain's auc: 0.775976\tdtrain's binary_logloss: 0.241359\tdvalid's auc: 0.697134\tdvalid's binary_logloss: 0.269871\n",
      "[75]\tdtrain's auc: 0.797685\tdtrain's binary_logloss: 0.234425\tdvalid's auc: 0.70293\tdvalid's binary_logloss: 0.26899\n",
      "[100]\tdtrain's auc: 0.815731\tdtrain's binary_logloss: 0.228814\tdvalid's auc: 0.704083\tdvalid's binary_logloss: 0.268868\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[125]\tdtrain's auc: 0.829581\tdtrain's binary_logloss: 0.224129\tdvalid's auc: 0.705665\tdvalid's binary_logloss: 0.268635\n",
      "[150]\tdtrain's auc: 0.842505\tdtrain's binary_logloss: 0.219803\tdvalid's auc: 0.708341\tdvalid's binary_logloss: 0.268341\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[175]\tdtrain's auc: 0.853362\tdtrain's binary_logloss: 0.215981\tdvalid's auc: 0.709571\tdvalid's binary_logloss: 0.268173\n",
      "[200]\tdtrain's auc: 0.863174\tdtrain's binary_logloss: 0.212191\tdvalid's auc: 0.709943\tdvalid's binary_logloss: 0.268051\n",
      "[225]\tdtrain's auc: 0.873044\tdtrain's binary_logloss: 0.20835\tdvalid's auc: 0.710075\tdvalid's binary_logloss: 0.268046\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[250]\tdtrain's auc: 0.88069\tdtrain's binary_logloss: 0.204939\tdvalid's auc: 0.709393\tdvalid's binary_logloss: 0.26819\n",
      "[275]\tdtrain's auc: 0.888608\tdtrain's binary_logloss: 0.201531\tdvalid's auc: 0.708721\tdvalid's binary_logloss: 0.268485\n",
      "Early stopping, best iteration is:\n",
      "[193]\tdtrain's auc: 0.860537\tdtrain's binary_logloss: 0.213211\tdvalid's auc: 0.710781\tdvalid's binary_logloss: 0.267907\n",
      "Fold 13, Valid score = 0.71078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8329, number of negative: 94425\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11874\n",
      "[LightGBM] [Info] Number of data points in the train set: 102754, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081058 -> initscore=-2.428062\n",
      "[LightGBM] [Info] Start training from score -2.428062\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.747926\tdtrain's binary_logloss: 0.25265\tdvalid's auc: 0.726571\tdvalid's binary_logloss: 0.249923\n",
      "[50]\tdtrain's auc: 0.774002\tdtrain's binary_logloss: 0.243068\tdvalid's auc: 0.732636\tdvalid's binary_logloss: 0.246182\n",
      "[75]\tdtrain's auc: 0.794644\tdtrain's binary_logloss: 0.236244\tdvalid's auc: 0.733235\tdvalid's binary_logloss: 0.245112\n",
      "[100]\tdtrain's auc: 0.811441\tdtrain's binary_logloss: 0.230785\tdvalid's auc: 0.735196\tdvalid's binary_logloss: 0.244627\n",
      "[125]\tdtrain's auc: 0.826429\tdtrain's binary_logloss: 0.22595\tdvalid's auc: 0.736629\tdvalid's binary_logloss: 0.244649\n",
      "[150]\tdtrain's auc: 0.839169\tdtrain's binary_logloss: 0.221664\tdvalid's auc: 0.735717\tdvalid's binary_logloss: 0.244668\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[175]\tdtrain's auc: 0.850639\tdtrain's binary_logloss: 0.217686\tdvalid's auc: 0.734027\tdvalid's binary_logloss: 0.245002\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tdtrain's auc: 0.861356\tdtrain's binary_logloss: 0.213834\tdvalid's auc: 0.732351\tdvalid's binary_logloss: 0.245316\n",
      "Early stopping, best iteration is:\n",
      "[114]\tdtrain's auc: 0.82066\tdtrain's binary_logloss: 0.227912\tdvalid's auc: 0.737482\tdvalid's binary_logloss: 0.244437\n",
      "Fold 14, Valid score = 0.73748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['CREDIT_DEBT', 'EDUCATION_LEVEL', 'FAMILY_STATUS', 'GENDER', 'NAME_CONTRACT_TYPE']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8302, number of negative: 94452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11969\n",
      "[LightGBM] [Info] Number of data points in the train set: 102754, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080795 -> initscore=-2.431595\n",
      "[LightGBM] [Info] Start training from score -2.431595\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tdtrain's auc: 0.748219\tdtrain's binary_logloss: 0.251938\tdvalid's auc: 0.725269\tdvalid's binary_logloss: 0.259008\n",
      "[50]\tdtrain's auc: 0.773506\tdtrain's binary_logloss: 0.242464\tdvalid's auc: 0.735362\tdvalid's binary_logloss: 0.25435\n",
      "[75]\tdtrain's auc: 0.794243\tdtrain's binary_logloss: 0.235646\tdvalid's auc: 0.739678\tdvalid's binary_logloss: 0.252923\n",
      "[100]\tdtrain's auc: 0.811365\tdtrain's binary_logloss: 0.230081\tdvalid's auc: 0.741358\tdvalid's binary_logloss: 0.252394\n",
      "[125]\tdtrain's auc: 0.827166\tdtrain's binary_logloss: 0.225331\tdvalid's auc: 0.740812\tdvalid's binary_logloss: 0.252483\n",
      "[150]\tdtrain's auc: 0.839793\tdtrain's binary_logloss: 0.221181\tdvalid's auc: 0.73984\tdvalid's binary_logloss: 0.252662\n",
      "[175]\tdtrain's auc: 0.851351\tdtrain's binary_logloss: 0.217128\tdvalid's auc: 0.739186\tdvalid's binary_logloss: 0.252651\n",
      "Early stopping, best iteration is:\n",
      "[90]\tdtrain's auc: 0.804559\tdtrain's binary_logloss: 0.232248\tdvalid's auc: 0.74153\tdvalid's binary_logloss: 0.252507\n",
      "Fold 15, Valid score = 0.74153\n",
      "Score by each fold: [0.71123, 0.73201, 0.72912, 0.73251, 0.7239, 0.73004, 0.73276, 0.73986, 0.73075, 0.73995, 0.71993, 0.71651, 0.71078, 0.73748, 0.74153]\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=15, random_state=1234123, shuffle=True)\n",
    "estimators, oof_preds = lightgbm_cross_validation(\n",
    "    params=lgb_params, X=train, y=target, cv=cv, categorical=categorical\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275234, 68)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(210977, 68)"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.loc[data['CREDIT_DEBT'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NAME_CONTRACT_TYPE', 'GENDER', 'EDUCATION_LEVEL', 'FAMILY_STATUS'], dtype='object')"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LightGBM Sklearn-API__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"n_estimators\": 10000,  # число деревьев\n",
    "    \"reg_lambda\": 100,  # регуляризация (то что используется при F2-штрафе (1:15:10))\n",
    "    #\"max_depth\": 4,  # глубина дерева\n",
    "    \"n_jobs\": 6,\n",
    "    \"seed\": 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial = list(categorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = KFold(n_splits=5, random_state=1234123, shuffle=True)\n",
    "# estimators, oof_preds = lightgbm_cross_validation(\n",
    "#     params=params, X=train, y=target, cv=cv, categorical=categorial\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72785\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score,5)}\")\n",
    "# Score by each fold: [0.71258, 0.73625, 0.72642, 0.73016, 0.731, 0.73805, 0.73708, 0.71603, 0.71426, 0.7362]\n",
    "# OOF-score = 0.72733\n",
    "# Score by each fold: [0.71352, 0.73414, 0.72961, 0.73237, 0.72938, 0.73352, 0.73783, 0.71175, 0.71819, 0.73926]\n",
    "# OOF-score = 0.72727\n",
    "# Score by each fold: [0.71123, 0.73201, 0.72912, 0.73251, 0.7239, 0.73004, 0.73276, 0.73986, 0.73075, 0.73995, 0.71993, 0.71651, 0.71078, 0.73748, 0.74153]\n",
    "# OOF-score = 0.72785"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.zeros(test.shape[0])\n",
    "# test[numerical] = test[numerical].astype(float)\n",
    "# test[categorial] = test[categorial].astype(int)\n",
    "\n",
    "for estimator in estimators:\n",
    "    y_pred += estimator.predict_proba(test)[:, 1] / len(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"APPLICATION_NUMBER\": test_id,\n",
    "    \"TARGET\": y_pred / cv.n_splits\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_id.shape)\n",
    "# test_id\n",
    "# estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_NUMBER</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110093</th>\n",
       "      <td>123724268</td>\n",
       "      <td>0.004655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110094</th>\n",
       "      <td>123456549</td>\n",
       "      <td>0.017125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110095</th>\n",
       "      <td>123428178</td>\n",
       "      <td>0.010461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110096</th>\n",
       "      <td>123619984</td>\n",
       "      <td>0.005617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110097</th>\n",
       "      <td>123671104</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110098</th>\n",
       "      <td>123632747</td>\n",
       "      <td>0.001666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110099</th>\n",
       "      <td>123728867</td>\n",
       "      <td>0.004418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110100</th>\n",
       "      <td>123459592</td>\n",
       "      <td>0.007612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110101</th>\n",
       "      <td>123595888</td>\n",
       "      <td>0.000651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110102</th>\n",
       "      <td>123480224</td>\n",
       "      <td>0.001838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        APPLICATION_NUMBER    TARGET\n",
       "110093           123724268  0.004655\n",
       "110094           123456549  0.017125\n",
       "110095           123428178  0.010461\n",
       "110096           123619984  0.005617\n",
       "110097           123671104  0.001215\n",
       "110098           123632747  0.001666\n",
       "110099           123728867  0.004418\n",
       "110100           123459592  0.007612\n",
       "110101           123595888  0.000651\n",
       "110102           123480224  0.001838"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"ILSokovnin_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
